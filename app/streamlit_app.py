# File: app/streamlit_app.py
"""
GDPP AI Docent - Streamlit ì±—ë´‡ UI
"""
import streamlit as st
import requests
import json
import sys
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ê¶ë””íŒ¡íŒ¡ AI ë„ìŠ¨íŠ¸",
    page_icon="ğŸ±",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ìŠ¤íƒ€ì¼ ì„¤ì •
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #FF6B6B;
        text-align: center;
        margin-bottom: 2rem;
    }
    .chat-message {
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
    }
    .user-message {
        background-color: #E3F2FD;
        margin-left: 20%;
    }
    .assistant-message {
        background-color: #F5F5F5;
        margin-right: 20%;
    }
    .source-box {
        background-color: #FFF9C4;
        padding: 0.5rem;
        border-radius: 0.3rem;
        margin-top: 0.5rem;
        font-size: 0.9rem;
    }
</style>
""", unsafe_allow_html=True)

# API ì„¤ì •
API_BASE_URL = "http://localhost:8000/api"

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

if "api_available" not in st.session_state:
    st.session_state.api_available = False


def check_api_status():
    """API ì„œë²„ ìƒíƒœ í™•ì¸"""
    try:
        response = requests.get(f"{API_BASE_URL}/status", timeout=5)
        if response.status_code == 200:
            return True, response.json()
        return False, None
    except:
        return False, None


def send_message(message: str, temperature: float = 0.7, top_k: int = 5):
    """ë©”ì‹œì§€ ì „ì†¡"""
    try:
        response = requests.post(
            f"{API_BASE_URL}/chat",
            json={
                "message": message,
                "temperature": temperature,
                "top_k": top_k
            },
            timeout=120
        )
        
        if response.status_code == 200:
            return response.json()
        else:
            return {"response": f"[ERROR] API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}", "sources": []}
    except Exception as e:
        return {"response": f"[ERROR] {str(e)}", "sources": []}


# í—¤ë”
st.markdown('<div class="main-header">ğŸ± ê¶ë””íŒ¡íŒ¡ AI ë„ìŠ¨íŠ¸</div>', unsafe_allow_html=True)
st.markdown("---")

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    # API ìƒíƒœ í™•ì¸
    if st.button("API ìƒíƒœ í™•ì¸"):
        is_available, status_data = check_api_status()
        st.session_state.api_available = is_available
        
        if is_available:
            st.success("API ì„œë²„ ì—°ê²°ë¨")
            
            # ìƒíƒœ ì •ë³´ í‘œì‹œ
            if status_data:
                st.json(status_data)
        else:
            st.error("API ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            st.info("ë°±ì—”ë“œ ì„œë²„ë¥¼ ì‹œì‘í•˜ì„¸ìš”:\n```bash\ncd /mnt/d/Project/GDDPAIDocent\npython -m uvicorn src.api.main:app --reload\n```")
    
    st.markdown("---")
    
    # íŒŒë¼ë¯¸í„° ì„¤ì •
    st.subheader("íŒŒë¼ë¯¸í„°")
    temperature = st.slider("Temperature", 0.0, 1.0, 0.7, 0.1)
    top_k = st.slider("ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ (Top K)", 1, 10, 5, 1)
    
    st.markdown("---")
    
    # ëŒ€í™” ì´ˆê¸°í™”
    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.rerun()
    
    st.markdown("---")
    
    # ì •ë³´
    st.subheader("ì •ë³´")
    st.markdown("""
    **ê¶ë””íŒ¡íŒ¡ AI ë„ìŠ¨íŠ¸**ëŠ” ìº£í˜ìŠ¤íƒ€ ë°©ë¬¸ê°ì„ ìœ„í•œ AI ì•ˆë‚´ ì±—ë´‡ì…ë‹ˆë‹¤.
    
    **ê¸°ëŠ¥:**
    - ë¸Œëœë“œ ì •ë³´ ê²€ìƒ‰
    - ì œí’ˆ ì¶”ì²œ
    - ë¶€ìŠ¤ ìœ„ì¹˜ ì•ˆë‚´
    - ê³ ì–‘ì´ ê´€ë ¨ ì§€ì‹ ì œê³µ
    
    **ì‚¬ìš© ì˜ˆì‹œ:**
    - "ê³ ì–‘ì´ ì‚¬ë£Œ ì¶”ì²œí•´ì¤˜"
    - "ê±´ê°•ë°±ì„œìº£ì— ëŒ€í•´ ì•Œë ¤ì¤˜"
    - "ê³ ì–‘ì´ í’ˆì¢…ì€ ì–´ë–¤ ê²ƒë“¤ì´ ìˆë‚˜ìš”?"
    """)

# ë©”ì¸ ì˜ì—­
col1, col2 = st.columns([3, 1])

with col1:
    st.subheader("ğŸ’¬ ëŒ€í™”")
    
    # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
    chat_container = st.container()
    
    with chat_container:
        for message in st.session_state.messages:
            role = message["role"]
            content = message["content"]
            
            if role == "user":
                st.markdown(f'<div class="chat-message user-message">ğŸ‘¤ **ì‚¬ìš©ì**: {content}</div>', unsafe_allow_html=True)
            else:
                st.markdown(f'<div class="chat-message assistant-message">ğŸ¤– **AI ë„ìŠ¨íŠ¸**: {content}</div>', unsafe_allow_html=True)
                
                # ì†ŒìŠ¤ ì •ë³´ í‘œì‹œ
                if "sources" in message and message["sources"]:
                    sources_text = "**ì°¸ê³  ìë£Œ:**\n"
                    for i, source in enumerate(message["sources"], 1):
                        sources_text += f"{i}. {source.get('title', 'Unknown')} (ì¶œì²˜: {source.get('source', 'Unknown')})\n"
                    
                    st.markdown(f'<div class="source-box">{sources_text}</div>', unsafe_allow_html=True)
    
    # ì…ë ¥ ì˜ì—­
    with st.form(key="chat_form", clear_on_submit=True):
        user_input = st.text_input(
            "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...",
            key="user_input",
            placeholder="ì˜ˆ: ê³ ì–‘ì´ ì‚¬ë£Œ ì¶”ì²œí•´ì¤˜"
        )
        
        submit_button = st.form_submit_button("ì „ì†¡")
    
    if submit_button and user_input:
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({
            "role": "user",
            "content": user_input
        })
        
        # API í˜¸ì¶œ
        with st.spinner("AI ë„ìŠ¨íŠ¸ê°€ ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            response_data = send_message(user_input, temperature, top_k)
        
        # AI ì‘ë‹µ ì¶”ê°€
        st.session_state.messages.append({
            "role": "assistant",
            "content": response_data.get("response", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."),
            "sources": response_data.get("sources", [])
        })
        
        # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
        st.rerun()

with col2:
    st.subheader("í†µê³„")
    
    # ëŒ€í™” í†µê³„
    total_messages = len(st.session_state.messages)
    user_messages = len([m for m in st.session_state.messages if m["role"] == "user"])
    
    st.metric("ì „ì²´ ë©”ì‹œì§€", total_messages)
    st.metric("ì‚¬ìš©ì ì§ˆë¬¸", user_messages)
    
    st.markdown("---")
    
    # ì¶”ì²œ ì§ˆë¬¸
    st.subheader("ğŸ’¡ ì¶”ì²œ ì§ˆë¬¸")
    
    sample_questions = [
        "ê³ ì–‘ì´ ì‚¬ë£Œ ì¶”ì²œí•´ì¤˜",
        "ê±´ê°•ë°±ì„œìº£ì— ëŒ€í•´ ì•Œë ¤ì¤˜",
        "ê³ ì–‘ì´ í’ˆì¢…ì€ ì–´ë–¤ ê²ƒë“¤ì´ ìˆë‚˜ìš”?",
        "ê³ ì–‘ì´ ê°„ì‹ ë¸Œëœë“œ ì•Œë ¤ì¤˜",
        "ê³ ì–‘ì´ ëª¨ë˜ ì¶”ì²œí•´ì¤˜"
    ]
    
    for question in sample_questions:
        if st.button(question, key=f"sample_{question}"):
            # ì§ˆë¬¸ ìë™ ì…ë ¥
            st.session_state.messages.append({
                "role": "user",
                "content": question
            })
            
            # API í˜¸ì¶œ
            with st.spinner("AI ë„ìŠ¨íŠ¸ê°€ ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                response_data = send_message(question, temperature, top_k)
            
            # AI ì‘ë‹µ ì¶”ê°€
            st.session_state.messages.append({
                "role": "assistant",
                "content": response_data.get("response", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."),
                "sources": response_data.get("sources", [])
            })
            
            st.rerun()

# í‘¸í„°
st.markdown("---")
st.markdown(
    '<div style="text-align: center; color: gray; font-size: 0.9rem;">'
    'Â© 2024 GDPP AI Docent | Powered by Local LLM + RAG'
    '</div>',
    unsafe_allow_html=True
)
